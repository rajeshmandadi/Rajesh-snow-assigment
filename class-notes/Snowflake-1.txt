*SNOWFLAKE CREDENTIALS:
              ->account name:urb44929.us-east-1  
			  ->username :Naidu
			  ->password: Naidu@1234
*AZURE CREDENTIALS:
              ->User name:rjms9866@gmail.com
			  ->password :Rajesh9866167759
			  
*AWS CREDENTIALS:
			  ->User name:rjms9866@gmail
			  ->password :Rajesh@9866167759
			  
	


1,what is mean by snowflake?
  -->snowflake is cloud based data warehouse introdued in 2012
  -->it is mainly used for data storage,data processing,analytical solution
  -->snowflake does not have their own infracture
  -->it built on top of the aws,azure,gcp
  -->it supported to strecture data,semi strecture,unstrecture data
  -->it is a saas modal (software as-a service)
2,what is mean by ETL AND ELT TOOLS?
  -->ETL stands for Extract transform load
  -->ELT stands for Extract load transform
  -->Informatica,talend,matillion,muelsoft
  
3,what is mean by sql -->sql means strecture query language, it is not a database, in order to communicate aney database we can use sql language
4,sub-language of sql-->
	--> DDL -->Data definaion language
		a,CREATE -->it is used to create database and table
		b,DROP -->it is used to drop the database and table
		c,ALTER: It is used to alter the structure of database (Table  3 1 column extra) 
	    d,TRUNCATE: It is used to remove all the records from a table 
	    e,COMMENT: It is used to add comments to the data dictonary 
	    f,RENAME: It is used to rename an objects existing in the database 
	--> DML --> Data Manipulation Language 
	    a,INSERT: It is used to insert the data into tables 
		b,UPDATE: It is used to update the existing data 
		c,DELETE: It is used to delete all records and particular records in a table 
    --> DQL --> Data Query Language
        a,SELECT:  It is used to retrive or display the records from database 
	
    --> DCL --> Data Control Language 
        a,GRANT: It is used to give user access /privileges to the database 
	    b,REVOKE: It is used to withdraws the User's access 
	
    --> TCL --> Transaction Cotrol Language 
        a,COMMIT: It is used to save transactions permanently 
	    b,ROLLBACK: It is used to revert the previuos tranactions before commit operations

 		
5,what is mean by database -->It is a collection of data     	{strecture(table,format),semi-strecture(json,xmlf),un-strecture}
6,what is mean by warehouse --> we are using to store the data but the purpose is different, 
                            --> historical data and analytical solution (large voulume of data)     							
7,data types --> INT/NUMBER,CHAR/VARCHAR/STRING(num,char), DATE/DECIMAL
8,What is mean by count(*)-->it display the all rows in table
9,what is mean by count(colum-name) -->it is used to excepted null values in a table

10,types of database-->MYSQL,ORACLE,DYNAMO-DB,MANGO-DB,POSTGRACE_SQL,HANA

11,What is mean by limit and offset?
    -->select * from employee
	   limit 1,  offset 5
	   -->limit 1 means display one (row) or (colum)
	   -->offset means display the after 5 rows (ex, 6)

12,Window functions:row_numbers-->it is unique values
	-->rank :two rows have same vales, rank also same,but next rank also skip accordingly
	-->dense_rank :two rows are same values,rank also same, but next rank is not skipped
	-->lag :it is used to display crrent row to previous row
	-->lead :it is used to display the current row to next rows
					
13,	Whatat is mean by sub_langguage ->it is used to query inside query is also sub-language
14,CASE	-->if,else
15,CTE  -->comman table expression

16,set operators  -->the sql set operations are used to combine the two or more sql select statement there 
					are four types
		-->UNION;it is used to display two more tables unique values only
				  ex;-->table-1 rajesh,satish,mastan
				     -->Table-2 rajesh,vamsi,sudhakar
					 output;rajesh,satish,mastan,vamsi,sudhakar
		-->UNION ALL;it is used to display both table information do not remove dupliccate values
				  ex;-->table-1 rajesh,satish,mastan
				     -->Table-2 rajesh,vamsi,sudhakar
					output;rajesh,rajesh,satish,mastan,vamsi,sudhakar
					
		-->minuse;
		-->intersect;it  display the both table common values
				  ex;-->table-1 rajesh,satish,mastan
				     -->Table-2 rajesh,vamsi,sudhakar
					output;rajesh,
-->LOGICAL OPERATORS:
		-->AND: The AND operator displays a record if all the conditions are TRUE.
		        EX:select first_name,last_name from employees
					where first_name like 'S%' and last_name like 'K%'

		-->OR: The OR operator displays a record if any of the conditions are TRUE.
		        EX:select first_name,last_name from employees
				   where first_name like 'D%' or last_name like 'S%';

		-->NOT: not operator is used to particular row not executed,
		        EX: select *  from employees
					where not first_name ='Steven'
		-->HAVING: HAVING is used to filter groups records.
		        EX:select first_name, count(*) from employees
				   group by first_name
				   having count(first_name) > 1
		-->GROUP_BY: The GROUP BY clause in SQL is used to group rows that have the same values in 	specified  columns in summary rows
				EX:select salary, count(*) from employees
					 group by salary
					 having count(salary) > 1

		-->ORDER BY: it print the output order wise (ASSENDING OR DESCNDING)
		            EX: select first_name from employees
						order by first_name
		-->DISTINCT:It print the unique values only fro one table 
					EX:  select distinct first_name from employees
		-->WHERE: it filter the records particular rows used to where condition
					EX:select * from employees
					   where employee_id = 100
17,AGGRIGATE FUNCTIONS :
		-->AVG:
		-->SUM:
		-->MIN:
		-->MAX:
		-->CONCAT:
		-->UPPER:
		-->LOWER:
		
18,SQL JIONS : It is used to display the data from two are more tables
		-->INNER JOIN; It print the matching values from both table 
						EX.SELECT E.FIRST_NAME,
						   E.LAST_NAME,
						   J.JOB_TITLE
						   FROM EMPLOYEES E
						   INNER JOIN JOBS AS J ON E.JOB_ID = J.JOB_ID

				
		-->RIGHT JOIN; Print the all values from right side table, then matched values from left
		side table
					 EX:   SELECT E.FIRST_NAME,
						   D.FIRST_NAME
						   FROM EMPLOYEES E
						   RIGHT OUTER JOIN DEPENDENTS AS D
						   ON E.FIRST_NAME = D.FIRST_NAME
       
		-->LEFT JOINN :IT print the all values from leftside table, then matched values from right side table             
					 EX.   SELECT E.FIRST_NAME,
						   D.FIRST_NAME
						   FROM EMPLOYEES E
						   LEFT OUTER JOIN DEPENDENTS AS D 
						   ON E.FIRST_NAME = D.LAST_NAME
						   
       
       
		-->FULL JOIN;  Print all rows from both table,if the matched values those rows will be merged,if there is no match null values include 
		            EX:SELECT E.FIRST_NAME,
					   D.FIRST_NAME
					   FROM EMPLOYEES E
					   FULL OUTER JOIN DEPENDENTS AS D
					   ON E.FIRST_NAME = D.FIRST_NAME
				  
		-->SELF JOIN;  Itâ€™s used to compare rows within the same table,
		
		
		-->CROSS JOIN; it print the values from both tales, especially with large tables.
		(N number of rows and N number of colums)cros multification 3*3 =9
		              EX: SELECT * FROM EMPLOYEES
						  CROSS JOIN JOBS
19,what is the difference between traditional warehouse and and snowflake
                  traditional WH                                snowflake
1,scalability ->scaling can be difficult and          ->it can easily enabiling scaling up and 
				often expensive                          down
2,cost        ->traditional wh separate cost          ->in snowflake there is now infracture cost
                 we need to pay for that         
3,data insert and
  retrive        ->we need to use ETL tools           ->we dont need to use aney tools we can use 
														  "copy" command
4,data backup ->we need to aditional storage       	  -> easily cloning,and no cost with cloning

5,data recovery->data is delete,retrive               ->data is delete, it is easily retrive 
                   is very difficult                    the data,time travel feature is available
6,data sharing->it is very difficult to sharing-data  -> it can easily to share the data

20,snowflake architecture  :there are 3 types of  architecture    

    a,storage layer   :-->data will be stored in columnar format
					   -->data will be stored in micro partitions
					   -->the data objects stored by snowflake canot directly visible are directly access by the customar 
					   -->we can also define cluster key on large data for better performance 

    b,query processing:-->This is the actual processing unit of snowflake 
					   -->snowflake process queries using virtual warehouse
                       -->compute cost will be calculated on the basis of query execution time
					      on virtual warehouse 
					   -->vm also scale up and scale down automatically
					   -->auto suspend and auto resume is available
	c,cloud service:   -->collection of service that cordinate activities across snowflake
					   -->This the brain of the snowflake
					   -->Authentication and access control layer
					   -->infracture management 
					   -->metadata management
					   -->security
21,NEW REPO	-->GIT COMMAND
    -->git init
    -->git add README.md
    -->git commit -m "first commit"
    -->git branch -M main
    -->git remote add origin git@github.com:rajeshmandadi/SQL-PRACTICE-.git
    -->git push -u origin main
22,OLD REPO    -->GIT COMMANDS
	-->git add
	-->git commit "first_commit"
    -->git push -u origin main
	
23,virtual server means: it means inside the server
24,snowflake editions: there are four types of editions
	-->Standard
	-->Enterprise 
	-->Business critical
	-->virtual private
25,Types of virtual warehouse sizes:XS,S,M,L,XL,2XL,3XL,4XL,5XL,6XL,

26,snowflake roles -->ACCOUNTADMIN
				   -->SECURITYADMIN
				   -->SYSADMIN
				   -->USERADMIN
				   -->PUBLIC 
				   -->ORGADMIN
27,stages in snowflake:They are two types of stages in snowflake 
	-->INTERNAL STAGE: we can load the data local system to snowflake, using to internal stages
	-->EXTERNAL STAGE: we can load the data cloud to snowflake, used to  external stage
28,PUT COMMAND:Put command is used to load the data into (internal-stage),put command only work 
				CLI,it not work to GUI,
29,COPY COMMAND: It is used to load the data stages to tables(INTERNAL/EXTERNAL)
30,COPY OPTIONS:
	-->VALIDATION_MODE:
	   1,RETURN_ERRORS:it return error rows only, 
	   (ex: copy into table name
	   from @stage name
	   file_format =(type =csv field_delimiter=','skip_header=1)
	   validation_mode = return_errors (or) return_all_records
	   2,RETURN_ALL_ERRORS:
	-->ON_ERRORS:
	  1,CONTINUE:Skip the error records,and load remaining records 
	    ex:ex: copy into table name
	   from @stage name
	   file_format =(type =csv field_delimiter=','skip_header=1)
	   on_errors = continue
	   
	  2,SKIP_FILE:Skip the error file.
	    ex: copy into table name
	    from @stage name
	    file_format =(type =csv field_delimiter=','skip_header=1)
	    on_errors = skip_file	
      3,SIZE_LIMIT:	Limits the maximum size of the staged data being loaded.   
	    ex:ex:ex: copy into table name
	    from @stage name
	    file_format =(type =csv field_delimiter=','skip_header=1)
	    size_limit = 10000	
	  4,FORCE: if already loaded,but again reload file	FORCE = TRUE
	    ex:copy into table name
			from @stage name
			file_format =(type = csv field_delimiter=','skip_header=1)
			force = TRUE
	  5,TRUNCATECOLUMNS :tuncatedcolumns and enforce_length both are same,The table definaion is wrong, used to truncatecolums = true 
	    ex:copy into table name
			from @stage name
			file_format =(type = csv field_delimiter=','skip_header=1)
			TRUNCATECOLUMNS = TRUE
	  6,ENFORCE_LENGTH: tuncatedcolumns and enforce_length both are same,The table definaion is wrong, used to truncatecolums = true

        ex:copy into table name
			from @stage name
			file_format =(type = csv field_delimiter=','skip_header=1)
			ENFORCE_LENGTH = False
	  7,PURG:it is used to  load the data (stage to table) after automatically remove the files in stage
	  ex:copy into table name
			from @stage name
			file_format =(type = csv field_delimiter=','skip_header=1)
			FURG = TRUE
			
31,HOW TO WORK SEMI-STRECTURE DATA AND HOW TO CONVERT TO TABLE FORMAT?
        HOW TO WORK ON JSON FORMAT TO TABLE FORMAT
		
    --CREATE EXTERNAL_STAGE--
    1,CREATE OR REPLACE STAGE RAJEHS
      S3 URL

    2,LIST @STAGE NAME

    3,CREATE TABLE JSON (RAW_FILE VARIANT)
--COPY DATA STAGE TO TABLE--

    4,COPY INTO JSON
    FROM @STAGENAME 
    FILE_FORMAT = (TYPE = JSON)

--RETRIEVE THE DATA JSON TO TABLE FORMAT--
    5,SELECT $1:FIRST_NAME,
             $1:LAST_NAME,
             $1:JOB_TITLE,
             $1:SALARY,
             $1:ID
             FROM JSON
  ---STORE THE DATA INTO NEW  TABLE--

       CREATE TABLE CSV_TABLE AS
       (
       ,SELECT $1:FIRST_NAME,
             $1:LAST_NAME,
             $1:JOB_TITLE,
             $1:SALARY,
             $1:ID
             FROM JSON
       )
    
    SELECT * FROM CSV_TABLE
32,HOW TO WORK ON ERROR RECORDS

    
	CREATE OR REPLACE EXTERNAL_STAGE
	S3 URL
	
	
	LIST @EXTERNAL_STAGE
	
	CREATE OR REPLACE TABLE ORDERS (
    ORDER_ID VARCHAR(30),
    AMOUNT INT,
    PROFIT INT,
    QUANTITY INT,
    CATEGORY VARCHAR(30),
    SUBCATEGORY VARCHAR(30));


	COPY INTO ORDERS 
	FROM @EXTERNAL_STAGE
	FILE_FORMAT = (TYPE =CSV FIELD_DELIMITER SKIP_HEADER=1)
	VALIDATION_MODE = RETURN_ERRORS
	
	--CREATE REJECTED RECORDS TABLE AND LOAD THE  REJECTED RECORDS
	CREATE OR REPLACE (REJECTED_RAJESH) AS
	SELECT REJECTED_RECORDS FROM TABLE (RESULT_SCAN(LAST_QUERY_ID()));
	
	--COPY INTO WITHOUT ERROR FILES IN ORDERS TABLE--
	
	COPY INTO TALE NAME
	FROM @EXTERNAL_STAGE NAME
	FILE_FORMAT =(TYPE=CSV FILE_DELIMITER=','SKIP_HEADER=1)
	ON_ERRORS = CONTINUE
	SELECT * FROM REJECTED_RECORD
	--SPLIT THE ERROR RECORDS AND LOAD THE TABLE--

	CREATE OR RELACE TABLE REJECTED2 AS 
	SELECT SPLIT_PART(REJECTED_RECORD,',',1) AS ORDER_ID,
	       SPLIT_PART(REJECTED_RECORD,',',2) AS AMOUNT,
		   SPLIT_PART(REJECTED_RECORD,',',3) AS PROFIT,
		   SPLIT_PART(REJECTED_RECORD,',',4) AS QUANTITY,
		   SPLIT_PART(REJECTED_RECORD,',',5) AS CATEGORY,
		   SPLIT_PART(REJECTED_RECORD,',',6) AS SUBCATEGORY
		   FROM REJECTED1;
	-- UPDATE THE ERROR RECORDS--	   
	UPDATE REJECTED2 
       SET PROFIT = 1000
    WHERE PROFIT = 'ONE THOUSEND'

    UPDATE REJECTED2
      SET PROFIT = 220
    WHERE PROFIT = 'TWO HUNDRED TWENTY'
    --FINALLY LOAD THE DATA INTO ORDERS TABLE 

  INSERT INTO ORDERS
   (SELECT * FROM REJECTED2)  
   
   
33,HOW TO INTEGRATED AWS TO SNOWFLAKE ?

1. Create AWS s3 bucket and load the files 
2. Create IAM Roles to access the files in AWS 
3. Create S3 integration 
4. Describe S3 integration and take the user ARN and External ID 
5. Modify the trust policy to add the ARN and eternal ID 
6. Create a stage (AWS Url) 
7. list to see how many files are there 
8. Create a table 
9. Perform copy to load the data (file foramt , copy options )

34,what is mean by snowfpipe --> snowpipe means continue dataflow and continue data intigration,
AWS,AZURE,GCP cloud bsed flatform

 
1. Create AWS s3 bucket and load the files 
2. Create IAM Roles to access the files in AWS 
3. Create S3 integration 
4. Describe S3 integration and take the user ARN and External ID 
5. Modify the trust policy to add the ARN and eternal ID 
6. Create a stage (AWS Url) 
7. list to see how many files are there 
8. Create a table 
9. Perform copy to load the data (file foramt , copy options )  to test 
10. Create a pipe and describe the pipe and configure pipe ARN into s3 properties as SQS
11. Resume/pause refresh a pipe  

35,WHAT IS MEAN BY TIME_TRAVEL -->we can retrive the data particular period of time,point in time recovery,in order to get histarical data (ex:by default data delete or modify we can use to retrive the data)

36,HOW MANY WAYS WE CAN RETRIEVE THE DATA -->There are 3 ways we can retrive the data 
         -->types of werehose editions and retention period
         -->default retention period is 1 day -->(standard edition)
		 -->default retention period is 90 day -->(enterrice edition)
         -->default retention period is 90 day -->(business critical edition)
         -->default retention period is 90 day -->(virtual edition)
		 -->After 90 days retention period is complete (file go to file safe 7 days retention period)
		 
		 -->default retention period is 1 day
		 -->you can set up to 90 days 
		 ex:select * from (table-name) data_retention_time_in_days =30,
		 
         -->offset-->it is used to retrive the data just 1,2 minutes back data only
		    
		 ex:create or replace table-name
		    (
		    select * from(able-name) at (offset => -60*1.5)
		 -->queryid --> it is used to retrive the data with query id
		 create or replace table table-name (
		 ex:select * form (table-name) before (statement => ueryid))
		 
		 -->timestamp-->it is used to retrive the data particular period of time (use time)
		 ex: create or replace table-name
		     (
			 select * from table-name before (timestamp => date,time ::timestamp))


37,TYPES OF TABLES ;There are 3 types of tables in snowflake
                     
		-->permanent table
		    -->Default table in snowflake
			-->these are the refgular and comman table in snowflake  
		    -->time travel retention period is 0 to 90 days (permanent table)
            -->file safe feature is avalable 7 days sotored
			-->We can't convert aney type of table to other table
			-->syntax to create permanent table
			    syntax:create table tablename (id int)
		-->transient table
			-->It is also similar to permanent table
			-->we can create transient database and transiant schema
		    -->we canot create permanent table name to transient table name
	     	-->We can't convert aney type of table to other table
			-->time travel retention period is 0 to 1 day only (transient table)
			-->ther is no file safe feature in transient table
			-->sysntax to create a transiant table(create transiant table tablename(id number)
		-->temporary table
			-->table exist only in this session
			    (ex:once you can lougt and login table is deleted no recovery options )
			-->canot create temporary database and temporary schema
			-->We can't convert aney type of table to other table
			-->
			-->we can create permanent table name to temporary table name 
			   (data fetched to temporary table)
			-->time travel retention period is 0 to 1 day only (temporary table)
			-->there is no file safe feature in temporary table
			-->table exist only in this session 
				(ex:once you can lougt and login table is deleted no recovery options ) 
            -->sysntax for temporary table (create temporary table tablename(id int)
			
			
38,ZERO COPY CLONING IN SNOWFLAKE:
            -->it means take backup of the TABLE,OR,SCHEMAS,OR,DATABASE
			-->we can take multiple copies of data,with no aditional cost that means "zero copy"
			-->the cloned objects is independent from original
			query;(create or replace table source tablename
			       clone destination table name)
			-->works with time travel also available